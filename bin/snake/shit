CONTIGS = ['DFM_001_F1_S8:DFM_002_F1_S9:DFM_003_F1_S10']
CONTIG2 = ['DFM_003_F1_S10:TFM_002_F1-1_S3:TFM_002_F1-2_S4-nik-mh']

##########################################################################################################
############################------------------BBMAP--------------------###################################
##########################################################################################################

rule bbmap:
    input:
        reads1 = 'data/reads/{sample}_R1.trim.fastq.gz',
        reads2 = 'data/reads/{sample}_R2.trim.fastq.gz',
        ref_ind = 'data/indexes/{index}'
    output:
        mapped = 'data/filt/human/{sample}:{index}.fa',
        unmapped1 = 'data/no_hum/{sample}:{index}.R1.fa',
        unmapped2 = 'data/no_hum/{sample}:{index}.R2.fa'
    log: 'log/bbmap/{sample}:{index}.log'
    benchmark: 'time/bbmap/{sample}:{index}.time.txt'
    threads: 8
    shell:
        """{config[bbmap.bin]} minid=0.93 maxindel=25 bwr=0.16 bw=12 quickmatch fast \
        minhits=2 qtrim=rl trimq=10 untrim -Xmx25g \
        path={input.ref_ind} in={input.reads1} in2={input.reads2} \
        outu1={output.unmapped1} outu2={output.unmapped2} \
        outm={output.mapped} threads={threads} \
        >{log} 2>&1"""
                
rule index_bbmap:
    input:
        ref = 'data/index-fasta/{index}.fa.gz'
    output:
        path = 'data/indexes/{index}'
    shell:
        '''{config[bbmap.bin]} ref={input.ref} path={output.path} -Xmx27g '''
        
        
##########################################################################################################
############################---------------GENERAL------------------###################################
##########################################################################################################    
rule kraken_gb:
    input:
        fa = 'data/ref/assemb/{ref}.fa'
    output: 
        krak = 'data/taxa/kraken/assemb/{ref}_gb.kraken'
    threads: 8
    shell: 
        '''{config[kraken.bin]} --preload \
        --db {config[kraken.db.gb]} \
        --threads {threads} \
        {input.fa} > {output.krak}'''
        
###########################################################################################################################################
###########################################-----------------------SOME SHIT---------------------###########################################
###########################################################################################################################################

# rule prepare_fai_and_dict:
#     input:
#         ref = 'data/ref/assemb/{contig}-{method}-community-{tool}.fa'
#     output:
#         fai = 'data/ref/assemb/{contig}-{method}-community-{tool}.fa.fai',
#         dictionary = 'data/ref/assemb/{contig}-{method}-community-{tool}.dict'
#     run:
#         shell('''echo -e "INFO: Creating fai and dict files for reference" \n
#                 samtools faidx {input.ref} \n
#                 {config[java.bin]} \
#                 -jar {config[picard.jar]} CreateSequenceDictionary \
#                 REFERENCE={input.ref} \
#                 OUTPUT={output.dictionary} \n
#                 echo -e "\nINFO: Step Completed!"''')  

#Mapping on ref
#
# rule create_bwa_index:
#     input:
#         ref = "data/ref/seq/{ref_set}.fa"
#     output:
#         folder = 'data/ref/index/bwa/{ref_set}/',
#         ref_o = 'data/ref/index/bwa/{ref_set}/{ref_set}.fa'
#     run:
#         shell('ln {input.ref} {output.ref_o}')
#         shell('bwa index -a bwtsw {output.ref_o}')

# rule map_on_ref_bwa:
#     input:
#         reads1 = 'data/reads/filtered/{method}/{sample}.R1.fa',
#         reads2 = 'data/reads/filtered/{method}/{sample}.R2.fa',
#         ref = 'data/ref/index/bwa/{reference}/reference.fa'
#     output:
#         sam = 'data/mapped/{reference}/bwa/{sample}.sam'
#     threads: 8
#     shell:
#         '''bwa mem -M -t {threads} {input.ref} {input.reads1} {input.reads2} > {output.sam}'''


# rule coverage_pileup:
#     input:
#         sam =  'data/snv/kumar/{contig}-{method}-{tool}/gatk_st/{sample}-{method}.realigned.bam',
#         ref = 'data/ref/assemb/{contig}-{method}-{tool}.fa'
#     output:
#         stats = 'data/snv/kumar/{contig}-{method}-{tool}/gatk_st/{sample}-{method}.realigned.bb_stats',
#         hist = 'data/snv/kumar/{contig}-{method}-{tool}/gatk_st/{sample}-{method}.realigned.bb_hist'
#     run:
#         shell('''/home/fedorov/tools/bbmap/pileup.sh ref={input.ref} in={input.sam} out={output.stats} hist={output.hist}''')

######--COVERAGE ESTIMATION--######      
# rule coverage_vcf_tools:
#     input:
#         vcf_file = 'data/snv/kumar/assemb/gatk_snp/{contig_name}/{sample}-{method}_vs_{contig}-{method}-{tool}-{ind_or_comm}.g.vcf'
#     output:
#         cov_file = 'data/snv/kumar/assemb/gatk_snp/{contig_name}/d1_{sample}-{method}_vs_{contig}-{method}-{tool}-{ind_or_comm}.idepth'
#     params:
#         file = 'data/snv/kumar/assemb/gatk_snp/{contig_name}/d1_{sample}-{method}_vs_{contig}-{method}-{tool}-{ind_or_comm}'
#     run:
#         shell('echo "working on {wildcards.contig_name} --> {wildcards.sample}"')
#         shell('vcftools --vcf {input.vcf_file} --depth --out {params.file} --minDP 1')

# rule coverage_vcf_tools_merged:
#     input:
#         vcf_file = 'data/snv/kumar/assemb/gatk_snp/{contig_name}/d1_{sample}-{method}_vs_{contig}-{method}-{tool}-{ind_or_comm}.idepth'
#     output:
#         cov_file = 'data/snv/kumar/assemb/gatk_snp/{contig_name}/{sample}-{method}_vs_{contig}-{method}-{tool}-{ind_or_comm}_d1.stats'
#     params:
#         wd = 'data/snv/kumar/assemb/gatk_snp/{contig_name}/'
#     run:
#         shell('echo "working on {wildcards.contig_name}"')
#         shell('echo -ne "{wildcards.contig_name}\t" > {params.wd}{wildcards.contig_name}_d1.stats && cat {params.wd}d1_*.idepth | grep -v "MEAN_DEPTH" | tr "\n" "\t" >> {output.cov_file}')
        
# rule cov_vcf_all:
#     input: expand('data/snv/kumar/assemb/gatk_snp/{contig_name}/d1_{sample}-nikita_vs_DFM_001_F1_S8:DFM_002_F1_S9:DFM_003_F1_S10-nikita-megahit-community.idepth', sample = TT,contig_name = CONTIGS_TO_CHECK)